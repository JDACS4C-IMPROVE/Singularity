{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037056e4baae4c4cbcdc55fd1f1f7476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c861d6b5018435abb86d0fadf2b7002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0165aa7f781f436cb7b65909dc2fa532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3033eeb42248b4aa9a7c77ec03316d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Part 1: Data Loading and Preprocessing\n",
    "\n",
    "# Download datasets (not necessary as we are using download=True in the next step)\n",
    "\n",
    "# # Define transformations for data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load Fashion MNIST dataset\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 200, Loss: 1.8664700442552566\n",
      "Epoch: 1, Batch: 400, Loss: 1.0202134603261948\n",
      "Epoch: 1, Batch: 600, Loss: 0.7619134965538978\n",
      "Epoch: 1, Batch: 800, Loss: 0.686231083869934\n",
      "Epoch: 2, Batch: 200, Loss: 0.5972450044751167\n",
      "Epoch: 2, Batch: 400, Loss: 0.5721162809431553\n",
      "Epoch: 2, Batch: 600, Loss: 0.5493666070699692\n",
      "Epoch: 2, Batch: 800, Loss: 0.5387066954374313\n",
      "Epoch: 3, Batch: 200, Loss: 0.5125240416824818\n",
      "Epoch: 3, Batch: 400, Loss: 0.4980582490563393\n",
      "Epoch: 3, Batch: 600, Loss: 0.49226638868451117\n",
      "Epoch: 3, Batch: 800, Loss: 0.46673306591808794\n",
      "Epoch: 4, Batch: 200, Loss: 0.45489336386322976\n",
      "Epoch: 4, Batch: 400, Loss: 0.45928189530968666\n",
      "Epoch: 4, Batch: 600, Loss: 0.4463480018079281\n",
      "Epoch: 4, Batch: 800, Loss: 0.44837641626596453\n",
      "Epoch: 5, Batch: 200, Loss: 0.4347141572088003\n",
      "Epoch: 5, Batch: 400, Loss: 0.4268411786854267\n",
      "Epoch: 5, Batch: 600, Loss: 0.42268663972616194\n",
      "Epoch: 5, Batch: 800, Loss: 0.42576565109193326\n",
      "Epoch: 6, Batch: 200, Loss: 0.40933271549642086\n",
      "Epoch: 6, Batch: 400, Loss: 0.4121618834137917\n",
      "Epoch: 6, Batch: 600, Loss: 0.4088550677895546\n",
      "Epoch: 6, Batch: 800, Loss: 0.4065160965919495\n",
      "Epoch: 7, Batch: 200, Loss: 0.3883725854754448\n",
      "Epoch: 7, Batch: 400, Loss: 0.39052835263311864\n",
      "Epoch: 7, Batch: 600, Loss: 0.39481120705604555\n",
      "Epoch: 7, Batch: 800, Loss: 0.39623687401413915\n",
      "Epoch: 8, Batch: 200, Loss: 0.37776733316481115\n",
      "Epoch: 8, Batch: 400, Loss: 0.38522033967077735\n",
      "Epoch: 8, Batch: 600, Loss: 0.3786325056105852\n",
      "Epoch: 8, Batch: 800, Loss: 0.38147825121879575\n",
      "Epoch: 9, Batch: 200, Loss: 0.37008737586438656\n",
      "Epoch: 9, Batch: 400, Loss: 0.3655026540160179\n",
      "Epoch: 9, Batch: 600, Loss: 0.3685040208697319\n",
      "Epoch: 9, Batch: 800, Loss: 0.37464527681469917\n",
      "Epoch: 10, Batch: 200, Loss: 0.3647588134557009\n",
      "Epoch: 10, Batch: 400, Loss: 0.36709562830626963\n",
      "Epoch: 10, Batch: 600, Loss: 0.36859486922621726\n",
      "Epoch: 10, Batch: 800, Loss: 0.3506047949939966\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Model Training\n",
    "\n",
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "net = Net()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 200}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 85.47%\n"
     ]
    }
   ],
   "source": [
    "# Part 3: Model Testing\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test set: {(100 * correct / total):.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Benchmarks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
